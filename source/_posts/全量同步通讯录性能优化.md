title: 全量同步通讯录性能优化
date: 2018-01-17 12:20:09
tags: [sqlite,node.js,nw.js]
---

早期企信的代码其实是惨不忍睹的, 随着用户量的提升, 初次登录全量同步通讯录的等待时间愈发的不可忍受. 这次记录一下优化通讯录全量同步的全过程.

<!-- more -->

运行环境: node-webkit 0.10.5 sqlite3 3.0.2 with sqlcipher
测试环境数据量: 组织架构 5800 用户数量 107059

1. 在新建sqlite连接时候, 不使用 `.verbose();` 记录日志, 根据数据量对sqlte的相关参数进行调整, 这将直接有效提升数据库插入性能,
2. 数据库切换到 `wal` 模式, 切换到wal模式后性能能够小许上升, 最关键的还是能够有效解决数据库锁的问题. 此外应该需要根据数据量控制wal模式的相关参数.
3. 批量数据插入时开启事务, 选择使用 `sqlite3-transactions` 库对sqlite3进行事务处理, 将组织架构批量插入和批量用户数据插入分别合为一个大事务.
4. 对重复循环的插入语句, 预先执行 `prepare` 命令. 这样能够减少内存占用以及进一步提升插入性能
5. 任何循环语句中的的逻辑都有着优化的可能, 所以需要对数据库相关操作的语法逻辑进行重构, 将有可能不会进入的语法进行提前的判断, 避免拷贝操作, 使用for循环替代.foreach, 使用 === 替代 == 等
6. 对全量更新数据库的逻辑进行优化, 原逻辑是当需要进行全量更新时先在原有数据库中对数据库执行 `DELETE` 操作, 然后再继续执行一遍全量数据库的操作.当数据库使用时间过长时, 会对数据库性能产生一定影响并会导致数据库文件过大. sqlite提供了`vacuum`和`analyze`能够改善这一情况, 但是更好的方式是在全量同步通讯录的时候新建一个新的数据库进行同步再替换原有数据库. 所以将逻辑改为每次全量同步时, 会新建一个新数据库原进行同步操作,  名字为contact-(当前时间).db, 将数据库名字进行保存, 同步完成后把原有数据库切换到新数据库中并删除原有数据库contact.db. 在每次启动企信的时候, 将读取保存记录是否有新数据库名称, 有则尝试更名读取的新库名contact-(当前时间).db为默认数据库contact.db并将记录中保存的数据库名称删除从而完成一个周期的全量更新数据以及数据迁移. 如果改名失败或删除失败, 则继续连接新库contact-(当前时间).db待下次启动再次进行相关操作.
7. 由于原来同步通讯录的逻辑是在主进程进行的, 初次全量同步时会伴随一系列并发逻辑, 影响性能, 同时由于V8引擎的落后, 在同步时往往占用大量内存不能及时回收, 我将代码进行抽离重写, 使得每次全量同步都在`fork`出来的新进程进行执行. 每个新进程都会占用10+mb运行环境空间, 但相比同步通讯录时上GB的内存占用则显得十分渺小. 此外需要注意的是nwjs在执行`fork`时其 process.versions内并不包含node-webkit的参数, 这会导致node_sqlite3无法使用. 对这一小坑需要调整node_sqlite3源码进行解决.
8. 由于使用新建数据库的方式, 可以在建表初期不创建主键以及索引, 并且在批量插入前使用 `PRAGMA synchronous = OFF` 关闭同步, 并在批量插入完成后创建`UNIQUE INDEX`并使用`PRAGMA synchronous = NORMAL`. 一些sqlite的相关参数也可以根据此方法在批量插入前进行设置. 在 sqlite 中 unique index 和 primary key 可以算是等效的, 详见 [http://www.sqlite.org/lang_createtable.html](http://www.sqlite.org/lang_createtable.html)
9. 传输格式上PC端使用json格式, 而移动端使用的是pb格式. 经对比, gzip压缩后的json格式大小与pb格式相差无几, json序列化耗时较pb快, 在内网环境下无疑灵活的json更合适. 可惜的是极致的优化需要服务端配合, 返回的json数据结构还有优化空间


经不断的优化在我这台开发小破机下全量同步通讯录耗时由最初的*300+*秒现在只需*18*秒 

